<!DOCTYPE html>
<html>

<head>
    <title>Most Recent Personal Projects</title>
    <link href="https://fonts.googleapis.com/css2?family=Cutive+Mono:wght@400;700&display=swap" rel="stylesheet">
    <style>
        body {
            font-family: 'Cutive Mono', monospace; /* Using the Space Mono font */
            background-color: #FFFFFF; /* White background */
            margin: 0;
            padding: 0;
            color: #000000; /* Black text */
        }

        .container {
            max-width: 800px;
            margin: 50px auto;
            padding: 20px;
        }

        .project {
            margin-bottom: 50px;
        }

        .project img {
            max-width: 100%; /* Make sure images scale properly */
            margin-bottom: 15px; /* A little space between the image and the text */
        }

        .project h2 {
            font-size: 24px;
            margin-bottom: 10px;
            color: #000000; /* Black for project titles */
        }

        .project p {
            font-size: 18px;
        }
    </style>
</head>

<body>
    <div class="container">
        <div class="project">
            <h2>Graph Neural Network Research</h2>
            <ul>
                <p>I cannot say too much here, but the bulk of my recent work at Atomic Industries was on deep graph neural networks and implementing methods on the graphs of part meshes for hierarchical learning. I employed various methods from discrete differential geometry and also my own personal algorithms for curvature and edge detection as additional features fed into the network as well. I think personally what is interesting is that graph neural networks do not require a fixed length input, and that they already have a relative positional embedding given by the adjacency matrix.</p>
                <!-- Add any relevant images here -->
                <img src="gnnimage.png" alt="3d part with edges highlighted">
            </ul>
        </div>
        <div class="project">
            <h2>Thrust Vectoring Solid Rocket Motor with Optimal Control</h2>
            <ul>
                <p>This project was a research capstone from my final year of mechanical engineering undergrad, where we set out to control a solid rocket motor with a gimbal. Generally speaking, this is quite easy for larger rockets
                    with liquid engines, since the rockets are heavier and have less thrust instability. This is why videos of thrust vector gimbals are often much slower and less entertaining. Here, we used optimal control with a linear quadratic regulator,
                    and the model was "trained" on the linear time invariant approximation to the aerodynamic differential equation in 2 dimensions (pitch and yaw). The experiment consisted of the same differential equation, but expressed as an inverted pendulum, which can actually
                    be proven to have the same dynamics (since damping is often small on rockets). A kalman filter was used prior to the the linear quadratic regulator to try to weight the open loop model with gyro sensor feedback to aid accuracy and cancel sensor noise covariance cross terms. Mathematically this was a highly interesting problem, and certainly the engineering design was fulfilling.</p>
                <img src="rocket.gif" alt="Thrust Vector Gimbal Test">
                <img src="rocket2.gif" alt="Thrust Vector Gimbal Test">
            </ul>
        </div>
        <div class="project">
            <h2>Physics Informed Neural Network to Solve the 1-D Burgers Equation</h2>
            <ul>
                <p>This is 1 dimensional burgers equation solution shown before and after training that was solved in PyTorch as a physics informed neural network. 
                    The way it works is that given the inputs to a PDE (x,t), the backpropagation allows the network to learn the solution u(x,t) to the PDE based on the conservation constraint given by the physics informed loss (usually just the PDE expressed as a homogenous equation), alongside the data driven loss. 
                    This problem only accepts fixed grids, which is an artifact of using a neural network. Currently I am working on methods such as physics informed neural operators which allow grids of any size within a margin by using the fourier transform. Other methods to deal with mesh-like inputs that have any tensor length are common in graph neural networks, which I have researched considerably at Atomic Industries. Top image represents domain initialization, bottom is after learning the PDE. </p>
                <img src="burg1.png" alt="Initialization of the domain">
                <img src="burg2.png" alt="Domain after learning the Burgers Equation">
            </ul>
        </div>
    </div>
</body>

</html>


